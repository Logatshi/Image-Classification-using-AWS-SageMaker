{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title: Image Classification Using AWS Sagemaker\n",
    "\n",
    "This notebook lists all the steps that you need to complete the complete this project. You will need to complete all the TODOs in this notebook as well as in the README and the two python scripts included with the starter code.\n",
    "\n",
    "\n",
    "**TODO**: Give a helpful introduction to what this notebook is for. Remember that comments, explanations and good documentation make your project informative and professional.\n",
    "\n",
    "**Note:** This notebook has a bunch of code and markdown cells with TODOs that you have to complete. These are meant to be helpful guidelines for you to finish your project while meeting the requirements in the project rubrics. Feel free to change the order of these the TODO's and use more than one TODO code cell to do all your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smdebug in /opt/conda/lib/python3.11/site-packages (1.0.34)\n",
      "Requirement already satisfied: protobuf<=3.20.3,>=3.20.0 in /opt/conda/lib/python3.11/site-packages (from smdebug) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.11/site-packages (from smdebug) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from smdebug) (24.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.11/site-packages (from smdebug) (1.35.49)\n",
      "Requirement already satisfied: pyinstrument==3.4.2 in /opt/conda/lib/python3.11/site-packages (from smdebug) (3.4.2)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.11/site-packages (from pyinstrument==3.4.2->smdebug) (0.2.4)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.49 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.10.32->smdebug) (1.35.49)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.10.32->smdebug) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.10.32->smdebug) (0.10.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.49->boto3>=1.10.32->smdebug) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.49->boto3>=1.10.32->smdebug) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.49->boto3>=1.10.32->smdebug) (1.16.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.3.1.post100)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (0.18.1a0+405940f)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.5)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (10.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (1.26.4)\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.35.49)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.49 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.35.49)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.49->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.49->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.49->boto3) (1.16.0)\n",
      "Requirement already satisfied: smdebug in /opt/conda/lib/python3.11/site-packages (1.0.34)\n",
      "Requirement already satisfied: bokeh in /opt/conda/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: protobuf<=3.20.3,>=3.20.0 in /opt/conda/lib/python3.11/site-packages (from smdebug) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.11/site-packages (from smdebug) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from smdebug) (24.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.11/site-packages (from smdebug) (1.35.49)\n",
      "Requirement already satisfied: pyinstrument==3.4.2 in /opt/conda/lib/python3.11/site-packages (from smdebug) (3.4.2)\n",
      "Requirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.11/site-packages (from pyinstrument==3.4.2->smdebug) (0.2.4)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.11/site-packages (from bokeh) (3.1.4)\n",
      "Requirement already satisfied: contourpy>=1.2 in /opt/conda/lib/python3.11/site-packages (from bokeh) (1.2.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from bokeh) (2.2.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.11/site-packages (from bokeh) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.11/site-packages (from bokeh) (6.0.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/conda/lib/python3.11/site-packages (from bokeh) (6.4.1)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /opt/conda/lib/python3.11/site-packages (from bokeh) (2024.9.0)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.49 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.10.32->smdebug) (1.35.49)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.10.32->smdebug) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.10.32->smdebug) (0.10.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from Jinja2>=2.9->bokeh) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->bokeh) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->bokeh) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->bokeh) (2024.1)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.49->boto3>=1.10.32->smdebug) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "# For instance, you will need the smdebug package\n",
    "!pip install smdebug\n",
    "# Install torch for working with PyTorch models\n",
    "!pip install torch torchvision\n",
    "# Install tqdm for progress bars\n",
    "!pip install tqdm\n",
    "# Install Pillow for image processing\n",
    "!pip install Pillow\n",
    "# Install numpy for numerical operations\n",
    "!pip install numpy\n",
    "# Install argparse if you plan on running the script locally from a terminal\n",
    "!pip install argparse\n",
    "# Install boto3 for S3 interactions \n",
    "!pip install boto3\n",
    "# Install bokeh for creating interactive visualizations in Python\n",
    "!pip install smdebug bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "# For instance you will need Boto3 and Sagemaker\n",
    "import os\n",
    "import boto3\n",
    "import IPython\n",
    "import sagemaker\n",
    "# Importing SageMaker components for role management, hyperparameter tuning, and model deployment\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter, IntegerParameter, HyperparameterTuner\n",
    "from sagemaker.pytorch import PyTorch\n",
    "# Debugger and Profiler configurations for SageMaker\n",
    "from sagemaker.debugger import Rule, DebuggerHookConfig, TensorBoardOutputConfig, CollectionConfig, ProfilerRule, rule_configs, ProfilerConfig, FrameworkProfile\n",
    "# Analytics for hyperparameter tuning jobs\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "# Importing specific PyTorch model and predictor from SageMaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "# Importing SageMaker Debugger and Profiler related tools\n",
    "from smdebug.core.modes import ModeKeys\n",
    "from smdebug.trials import create_trial\n",
    "# Utilities for visualizing training job performance and analysis\n",
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "# For plotting and visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "# For image processing\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "TODO: Explain what dataset you are using for this project. Maybe even give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understand of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-27 10:30:56--  https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
      "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.193.16, 52.219.113.120, 52.219.220.232, ...\n",
      "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.193.16|:443... connected.\n",
      "WARNING: cannot verify s3-us-west-1.amazonaws.com's certificate, issued by ‘CN=Amazon RSA 2048 M01,O=Amazon,C=US’:\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1132023110 (1.1G) [application/zip]\n",
      "Saving to: ‘dogImages.zip’\n",
      "\n",
      "dogImages.zip       100%[===================>]   1.05G  47.8MB/s    in 23s     \n",
      "\n",
      "2024-10-27 10:31:20 (46.0 MB/s) - ‘dogImages.zip’ saved [1132023110/1132023110]\n",
      "\n",
      "Archive:  dogImages.zip\n"
     ]
    }
   ],
   "source": [
    "# Command to download and unzip data\n",
    "!wget --no-check-certificate https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!unzip -f dogImages.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('dogImages.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-us-east-1-637163362320\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::637163362320:role/service-role/AmazonSageMaker-ExecutionRole-20241026T151604\n",
      "input: s3://sagemaker-us-east-1-637163362320/dogImages\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "# Initialize a SageMaker session to manage resources\n",
    "session = sagemaker.Session()\n",
    "# Get the default S3 bucket for the session\n",
    "bucket = session.default_bucket()\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "# Retrieve the AWS region for the session\n",
    "region = session.boto_region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "# Get the IAM role that SageMaker will use to access resources\n",
    "role = sagemaker.get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "# Define a prefix for organizing uploaded data in S3\n",
    "prefix = \"dogImages\"  \n",
    "# Upload the local dogImages directory to S3\n",
    "inputs = session.upload_data(path=\"./dogImages\", bucket=bucket, key_prefix=prefix)\n",
    "print(f\"input: {inputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "**TODO:** This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "**Note:** You will need to use the `hpo.py` script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Declare your HP ranges, metrics etc.\n",
    "from sagemaker.tuner import ContinuousParameter, IntegerParameter, CategoricalParameter\n",
    "\n",
    "# Define hyperparameter ranges for tuning\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),  \n",
    "    \"batch_size\": CategoricalParameter([16, 64]), \n",
    "    \"epochs\": IntegerParameter(5, 10),  \n",
    "}\n",
    "# The objective metric to be used by the Hyperparameter Tuning jobs is the Test Accuracy of the model on the validation dataset\n",
    "objective_metric_name = \"Accuracy\"\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [{\"Name\": \"Accuracy\", \"Regex\": \"Test Loss: .*? Accuracy: ([0-9\\\\.]+)%\"}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create estimators for your HPs\n",
    "# Define the PyTorch estimator with your configuration\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\"\n",
    ")\n",
    "# Configuring the estimated to run 6 total hyperparameter tuner jobs with an allowed parallel job count of 2\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator = estimator,\n",
    "    objective_metric_name = objective_metric_name,\n",
    "    early_stopping_type = \"Auto\",\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    metric_definitions = metric_definitions,\n",
    "    max_jobs=6,\n",
    "    max_parallel_jobs=2,\n",
    "    objective_type = objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your HP Tuner\n",
    "tuner.fit({'training': inputs, 'validation': inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-10-27 15:44:32 Starting - Preparing the instances for training\n",
      "2024-10-27 15:44:32 Downloading - Downloading the training image\n",
      "2024-10-27 15:44:32 Training - Training image download completed. Training in progress.\n",
      "2024-10-27 15:44:32 Uploading - Uploading generated training model\n",
      "2024-10-27 15:44:32 Completed - Resource reused by training job: pytorch-training-241027-1519-003-db3d7d00\n",
      "{'_tuning_objective_metric': '\"Accuracy\"', 'batch_size': '\"64\"', 'epochs': '9', 'lr': '0.001506843104990693', 'sagemaker_container_log_level': '20', 'sagemaker_estimator_class_name': '\"PyTorch\"', 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"', 'sagemaker_job_name': '\"pytorch-training-2024-10-27-15-19-28-505\"', 'sagemaker_program': '\"hpo.py\"', 'sagemaker_region': '\"us-east-1\"', 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-15-19-28-505/source/sourcedir.tar.gz\"'}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Get the best estimators and the best HPs\n",
    "# Retrieve the best estimator from the tuning job\n",
    "best_estimator = tuner.best_estimator()\n",
    "# Get the hyperparameters of the best trained model\n",
    "best_hyperparameters = best_estimator.hyperparameters()\n",
    "print(best_hyperparameters)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "**Note:** You will need to use the `train_model.py` script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_tuning_objective_metric': '\"Accuracy\"', 'batch_size': '\"64\"', 'epochs': '9', 'lr': '0.001506843104990693', 'sagemaker_container_log_level': '20', 'sagemaker_estimator_class_name': '\"PyTorch\"', 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"', 'sagemaker_job_name': '\"pytorch-training-2024-10-27-15-19-28-505\"', 'sagemaker_program': '\"hpo.py\"', 'sagemaker_region': '\"us-east-1\"', 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-15-19-28-505/source/sourcedir.tar.gz\"'}\n"
     ]
    }
   ],
   "source": [
    "print(best_estimator.hyperparameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch-size': 64, 'epochs': 9, 'lr': 0.001506843104990693}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks \n",
    "\n",
    "from sagemaker.debugger import DebuggerHookConfig, Rule, CollectionConfig\n",
    "from sagemaker.debugger import rule_configs\n",
    "\n",
    "# Extracting the best hyperparameters\n",
    "best_hyperparameters = {\n",
    "    \"batch-size\": int(best_estimator.hyperparameters()[\"batch_size\"].replace('\"', \"\")),   \n",
    "    \"epochs\": int(best_estimator.hyperparameters()[\"epochs\"]),   \n",
    "    \"lr\": float(best_estimator.hyperparameters()[\"lr\"]),  \n",
    "}\n",
    "\n",
    "print(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework profiling will be deprecated from tensorflow 2.12 and pytorch 2.0 in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Define rules for profiling\n",
    "from sagemaker.debugger import DebuggerHookConfig, Rule, CollectionConfig, ProfilerConfig, FrameworkProfile\n",
    "from sagemaker.debugger import rule_configs, ProfilerRule\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "\n",
    "debugger_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_model.py\",\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    hyperparameters=best_hyperparameters,\n",
    "    rules=rules,\n",
    "    profiler_config=profiler_config,\n",
    "    debugger_hook_config=debugger_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-10-27-17-40-03-028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-27 17:40:06 Starting - Starting the training job...\n",
      "2024-10-27 17:40:35 Starting - Preparing the instances for trainingVanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: InProgress\n",
      "ProfilerReport: InProgress\n",
      "...\n",
      "2024-10-27 17:40:55 Downloading - Downloading input data......\n",
      "2024-10-27 17:41:55 Downloading - Downloading the training image..................\n",
      "2024-10-27 17:44:55 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-10-27 17:44:55,547 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-10-27 17:44:55,580 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-10-27 17:44:55,584 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-10-27 17:44:55,882 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 9,\n",
      "        \"lr\": 0.001506843104990693\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2024-10-27-17-40-03-028\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-17-40-03-028/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":9,\"lr\":0.001506843104990693}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-17-40-03-028/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":9,\"lr\":0.001506843104990693},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2024-10-27-17-40-03-028\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-17-40-03-028/source/sourcedir.tar.gz\",\"module_name\":\"train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"9\",\"--lr\",\"0.001506843104990693\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=9\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001506843104990693\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_model.py --batch-size 64 --epochs 9 --lr 0.001506843104990693\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:00.391 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:00.433 algo-1:33 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:00.434 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:00.436 algo-1:33 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:00.437 algo-1:33 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:00.438 algo-1:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.105 algo-1:33 INFO hook.py:591] name:conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.106 algo-1:33 INFO hook.py:591] name:bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.106 algo-1:33 INFO hook.py:591] name:bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.107 algo-1:33 INFO hook.py:591] name:layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.107 algo-1:33 INFO hook.py:591] name:layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.108 algo-1:33 INFO hook.py:591] name:layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.108 algo-1:33 INFO hook.py:591] name:layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.109 algo-1:33 INFO hook.py:591] name:layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.109 algo-1:33 INFO hook.py:591] name:layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.110 algo-1:33 INFO hook.py:591] name:layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.110 algo-1:33 INFO hook.py:591] name:layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.111 algo-1:33 INFO hook.py:591] name:layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.111 algo-1:33 INFO hook.py:591] name:layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.112 algo-1:33 INFO hook.py:591] name:layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.112 algo-1:33 INFO hook.py:591] name:layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.112 algo-1:33 INFO hook.py:591] name:layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.125 algo-1:33 INFO hook.py:591] name:layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.125 algo-1:33 INFO hook.py:591] name:layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.126 algo-1:33 INFO hook.py:591] name:layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.126 algo-1:33 INFO hook.py:591] name:layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.127 algo-1:33 INFO hook.py:591] name:layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.127 algo-1:33 INFO hook.py:591] name:layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.127 algo-1:33 INFO hook.py:591] name:layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.128 algo-1:33 INFO hook.py:591] name:layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.128 algo-1:33 INFO hook.py:591] name:layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.129 algo-1:33 INFO hook.py:591] name:layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.129 algo-1:33 INFO hook.py:591] name:layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.130 algo-1:33 INFO hook.py:591] name:layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.130 algo-1:33 INFO hook.py:591] name:layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.131 algo-1:33 INFO hook.py:591] name:layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.132 algo-1:33 INFO hook.py:591] name:layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.132 algo-1:33 INFO hook.py:591] name:layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.133 algo-1:33 INFO hook.py:591] name:layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.133 algo-1:33 INFO hook.py:591] name:layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.134 algo-1:33 INFO hook.py:591] name:layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.135 algo-1:33 INFO hook.py:591] name:layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.135 algo-1:33 INFO hook.py:591] name:layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.136 algo-1:33 INFO hook.py:591] name:layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.137 algo-1:33 INFO hook.py:591] name:layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.137 algo-1:33 INFO hook.py:591] name:layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.138 algo-1:33 INFO hook.py:591] name:layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.138 algo-1:33 INFO hook.py:591] name:layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.139 algo-1:33 INFO hook.py:591] name:layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.140 algo-1:33 INFO hook.py:591] name:layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.140 algo-1:33 INFO hook.py:591] name:layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.141 algo-1:33 INFO hook.py:591] name:layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.141 algo-1:33 INFO hook.py:591] name:layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.142 algo-1:33 INFO hook.py:591] name:layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.142 algo-1:33 INFO hook.py:591] name:layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.143 algo-1:33 INFO hook.py:591] name:layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.144 algo-1:33 INFO hook.py:591] name:layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.144 algo-1:33 INFO hook.py:591] name:layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.145 algo-1:33 INFO hook.py:591] name:layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.145 algo-1:33 INFO hook.py:591] name:layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.146 algo-1:33 INFO hook.py:591] name:layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.147 algo-1:33 INFO hook.py:591] name:layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.147 algo-1:33 INFO hook.py:591] name:layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.148 algo-1:33 INFO hook.py:591] name:layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.148 algo-1:33 INFO hook.py:591] name:layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.149 algo-1:33 INFO hook.py:591] name:layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.150 algo-1:33 INFO hook.py:591] name:fc.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.150 algo-1:33 INFO hook.py:591] name:fc.bias count_params:3\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.151 algo-1:33 INFO hook.py:593] Total Trainable Params: 11178051\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.152 algo-1:33 INFO hook.py:425] Monitoring the collections: gradients, losses, relu_input\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.154 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/prestepzero-*-start-1730051100433761.0_global-0-stepstart-1730051103153535.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:03.165 algo-1:33 INFO hook.py:488] Hook is writing from the hook with pid: 33\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:15.445 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-0-stepstart-1730051103161375.8_global-0-forwardpassend-1730051115445289.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:16.209 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-0-forwardpassend-1730051115448559.5_global-1-stepstart-1730051116208194.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:17.782 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-1-stepstart-1730051116214307.5_global-1-forwardpassend-1730051117781592.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:17.954 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-1-forwardpassend-1730051117783901.5_global-2-stepstart-1730051117952436.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:18.917 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-2-stepstart-1730051117957086.8_global-2-forwardpassend-1730051118916829.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:19.092 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-2-forwardpassend-1730051118918821.2_global-3-stepstart-1730051119092388.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:20.065 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-3-stepstart-1730051119096177.0_global-3-forwardpassend-1730051120064795.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:20.247 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-3-forwardpassend-1730051120067083.5_global-4-stepstart-1730051120246294.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:21.257 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-4-stepstart-1730051120252658.2_global-4-forwardpassend-1730051121256891.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:21.437 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-4-forwardpassend-1730051121259055.8_global-5-stepstart-1730051121436266.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:22.518 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-5-stepstart-1730051121440744.8_global-5-forwardpassend-1730051122518476.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:22.684 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-5-forwardpassend-1730051122520371.5_global-6-stepstart-1730051122684068.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:23.560 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-6-stepstart-1730051122686586.8_global-6-forwardpassend-1730051123560578.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:23.733 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-6-forwardpassend-1730051123562213.5_global-7-stepstart-1730051123732467.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:24.613 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-7-stepstart-1730051123735936.5_global-7-forwardpassend-1730051124613532.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:24.783 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-7-forwardpassend-1730051124615308.5_global-8-stepstart-1730051124783158.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:25.667 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-8-stepstart-1730051124786526.0_global-8-forwardpassend-1730051125667253.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:25.843 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-8-forwardpassend-1730051125668962.2_global-9-stepstart-1730051125842793.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:26.720 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-9-stepstart-1730051125846341.8_global-9-forwardpassend-1730051126720298.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2024-10-27 17:45:26.891 algo-1:33 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/33-algo-1/global-9-forwardpassend-1730051126722028.0_global-10-stepstart-1730051126891045.8/python_stats.\u001b[0m\n",
      "\u001b[34mEpoch [1/9], Loss: 0.696258085829611\u001b[0m\n",
      "\u001b[34mEpoch [2/9], Loss: 0.6636952134489104\u001b[0m\n",
      "\u001b[34mEpoch [3/9], Loss: 0.6523876940931073\u001b[0m\n",
      "VanishingGradient: InProgress\n",
      "Overfit: InProgress\n",
      "Overtraining: InProgress\n",
      "PoorWeightInitialization: IssuesFound\n",
      "\u001b[34mEpoch [4/9], Loss: 0.6532827922861084\u001b[0m\n",
      "\u001b[34mEpoch [5/9], Loss: 0.6544686596812183\u001b[0m\n",
      "\u001b[34mEpoch [6/9], Loss: 0.6503796843627027\u001b[0m\n",
      "\u001b[34mEpoch [7/9], Loss: 0.6502989890011213\u001b[0m\n",
      "\u001b[34mEpoch [8/9], Loss: 0.6514450518684533\u001b[0m\n",
      "\u001b[34mEpoch [9/9], Loss: 0.6515839156758694\u001b[0m\n",
      "\u001b[34mModel saved at /opt/ml/model/model.pth\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 79%|███████▉  | 35.4M/44.7M [00:00<00:00, 372MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 375MB/s]\u001b[0m\n",
      "\u001b[34m2024-10-27 17:51:53,201 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-10-27 17:52:16 Uploading - Uploading generated training model\n",
      "2024-10-27 17:52:16 Completed - Training job completed\n",
      "Training seconds: 683\n",
      "Billable seconds: 683\n"
     ]
    }
   ],
   "source": [
    "# Fit an estimator\n",
    "estimator.fit({\"training\": inputs}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-training-2024-10-27-17-40-03-028\n",
      "us-east-1\n",
      "{'TrainingJobName': 'pytorch-training-2024-10-27-17-40-03-028', 'TrainingJobArn': 'arn:aws:sagemaker:us-east-1:637163362320:training-job/pytorch-training-2024-10-27-17-40-03-028', 'ModelArtifacts': {'S3ModelArtifacts': 's3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-17-40-03-028/output/model.tar.gz'}, 'TrainingJobStatus': 'Completed', 'SecondaryStatus': 'Completed', 'HyperParameters': {'batch-size': '64', 'epochs': '9', 'lr': '0.001506843104990693', 'sagemaker_container_log_level': '20', 'sagemaker_job_name': '\"pytorch-training-2024-10-27-17-40-03-028\"', 'sagemaker_program': '\"train_model.py\"', 'sagemaker_region': '\"us-east-1\"', 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-17-40-03-028/source/sourcedir.tar.gz\"'}, 'AlgorithmSpecification': {'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.8-gpu-py36', 'TrainingInputMode': 'File', 'EnableSageMakerMetricsTimeSeries': True}, 'RoleArn': 'arn:aws:iam::637163362320:role/service-role/AmazonSageMaker-ExecutionRole-20241026T151604', 'InputDataConfig': [{'ChannelName': 'training', 'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-637163362320/dogImages', 'S3DataDistributionType': 'FullyReplicated'}}, 'CompressionType': 'None', 'RecordWrapperType': 'None'}], 'OutputDataConfig': {'KmsKeyId': '', 'S3OutputPath': 's3://sagemaker-us-east-1-637163362320/', 'CompressionType': 'GZIP'}, 'ResourceConfig': {'InstanceType': 'ml.g4dn.xlarge', 'InstanceCount': 1, 'VolumeSizeInGB': 30}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'CreationTime': datetime.datetime(2024, 10, 27, 17, 40, 3, 409000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2024, 10, 27, 17, 40, 47, 854000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 10, 27, 17, 52, 10, 313000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2024, 10, 27, 17, 55, 17, 551000, tzinfo=tzlocal()), 'SecondaryStatusTransitions': [{'Status': 'Starting', 'StartTime': datetime.datetime(2024, 10, 27, 17, 40, 3, 409000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 10, 27, 17, 40, 47, 854000, tzinfo=tzlocal()), 'StatusMessage': 'Preparing the instances for training'}, {'Status': 'Downloading', 'StartTime': datetime.datetime(2024, 10, 27, 17, 40, 47, 854000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 10, 27, 17, 44, 45, 777000, tzinfo=tzlocal()), 'StatusMessage': 'Downloading the training image'}, {'Status': 'Training', 'StartTime': datetime.datetime(2024, 10, 27, 17, 44, 45, 777000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 10, 27, 17, 51, 57, 754000, tzinfo=tzlocal()), 'StatusMessage': 'Training image download completed. Training in progress.'}, {'Status': 'Uploading', 'StartTime': datetime.datetime(2024, 10, 27, 17, 51, 57, 754000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 10, 27, 17, 52, 10, 313000, tzinfo=tzlocal()), 'StatusMessage': 'Uploading generated training model'}, {'Status': 'Completed', 'StartTime': datetime.datetime(2024, 10, 27, 17, 52, 10, 313000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 10, 27, 17, 52, 10, 313000, tzinfo=tzlocal()), 'StatusMessage': 'Training job completed'}], 'EnableNetworkIsolation': False, 'EnableInterContainerTrafficEncryption': False, 'EnableManagedSpotTraining': False, 'TrainingTimeInSeconds': 683, 'BillableTimeInSeconds': 683, 'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-637163362320/', 'HookParameters': {'eval.save_interval': '10', 'train.save_interval': '100'}, 'CollectionConfigurations': [{'CollectionName': 'gradients', 'CollectionParameters': {'save_interval': '500'}}, {'CollectionName': 'relu_input', 'CollectionParameters': {'include_regex': '.*relu_input', 'save_interval': '500'}}]}, 'DebugRuleConfigurations': [{'RuleConfigurationName': 'VanishingGradient', 'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest', 'VolumeSizeInGB': 0, 'RuleParameters': {'rule_to_invoke': 'VanishingGradient'}}, {'RuleConfigurationName': 'Overfit', 'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest', 'VolumeSizeInGB': 0, 'RuleParameters': {'rule_to_invoke': 'Overfit'}}, {'RuleConfigurationName': 'Overtraining', 'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest', 'VolumeSizeInGB': 0, 'RuleParameters': {'rule_to_invoke': 'Overtraining'}}, {'RuleConfigurationName': 'PoorWeightInitialization', 'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest', 'VolumeSizeInGB': 0, 'RuleParameters': {'rule_to_invoke': 'PoorWeightInitialization'}}], 'DebugRuleEvaluationStatuses': [{'RuleConfigurationName': 'VanishingGradient', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:637163362320:processing-job/pytorch-training-2024-10-2-VanishingGradient-04e81fc4', 'RuleEvaluationStatus': 'NoIssuesFound', 'LastModifiedTime': datetime.datetime(2024, 10, 27, 17, 52, 56, 632000, tzinfo=tzlocal())}, {'RuleConfigurationName': 'Overfit', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:637163362320:processing-job/pytorch-training-2024-10-2-Overfit-5111309e', 'RuleEvaluationStatus': 'NoIssuesFound', 'LastModifiedTime': datetime.datetime(2024, 10, 27, 17, 52, 56, 632000, tzinfo=tzlocal())}, {'RuleConfigurationName': 'Overtraining', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:637163362320:processing-job/pytorch-training-2024-10-2-Overtraining-dbdce7dc', 'RuleEvaluationStatus': 'NoIssuesFound', 'LastModifiedTime': datetime.datetime(2024, 10, 27, 17, 52, 56, 632000, tzinfo=tzlocal())}, {'RuleConfigurationName': 'PoorWeightInitialization', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:637163362320:processing-job/pytorch-training-2024-10-2-PoorWeightInitialization-1236f254', 'RuleEvaluationStatus': 'IssuesFound', 'StatusDetails': 'RuleEvaluationConditionMet: Evaluation of the rule PoorWeightInitialization at step 0 resulted in the condition being met\\n', 'LastModifiedTime': datetime.datetime(2024, 10, 27, 17, 52, 56, 632000, tzinfo=tzlocal())}], 'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-637163362320/', 'ProfilingIntervalInMilliseconds': 500, 'ProfilingParameters': {'DataloaderProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, \"MetricsRegex\": \".*\", }', 'DetailedProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }', 'FileOpenFailThreshold': '50', 'HorovodProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }', 'LocalPath': '/opt/ml/output/profiler', 'PythonProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, \"ProfilerName\": \"cprofile\", \"cProfileTimer\": \"total_time\", }', 'RotateFileCloseIntervalInSeconds': '60', 'RotateMaxFileSizeInBytes': '10485760', 'SMDataParallelProfilingConfig': '{\"StartStep\": 0, \"NumSteps\": 10, }'}, 'DisableProfiler': False}, 'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport', 'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest', 'VolumeSizeInGB': 0, 'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}], 'ProfilerRuleEvaluationStatuses': [{'RuleConfigurationName': 'ProfilerReport', 'RuleEvaluationJobArn': 'arn:aws:sagemaker:us-east-1:637163362320:processing-job/pytorch-training-2024-10-2-ProfilerReport-c986ca4d', 'RuleEvaluationStatus': 'IssuesFound', 'StatusDetails': 'RuleEvaluationConditionMet: Evaluation of the rule ProfilerReport at step 12 resulted in the condition being met\\n', 'LastModifiedTime': datetime.datetime(2024, 10, 27, 17, 55, 17, 548000, tzinfo=tzlocal())}], 'ProfilingStatus': 'Enabled', 'ResponseMetadata': {'RequestId': '80b674fa-a523-4f6e-8ace-bde794fb80b7', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '80b674fa-a523-4f6e-8ace-bde794fb80b7', 'content-type': 'application/x-amz-json-1.1', 'content-length': '6950', 'date': 'Sun, 27 Oct 2024 18:22:45 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Plot a debugging output.\n",
    "training_job_name = estimator.latest_training_job.name\n",
    "client = estimator.sagemaker_session.sagemaker_client\n",
    "description = client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "print(training_job_name)\n",
    "print(region)\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profiler output s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-17-40-03-028/rule-output\n"
     ]
    }
   ],
   "source": [
    "# TODO: Display the profiler output\n",
    "\n",
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "print(f\"profiler output {rule_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-17-40-03-028/output/model.tar.gz), script artifact (s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-17-40-03-028/source/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-637163362320/pytorch-training-2024-10-27-18-24-52-100/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-training-2024-10-27-18-24-52-100\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-training-2024-10-27-18-24-52-100\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-training-2024-10-27-18-24-52-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "\n",
    "# Specify instance type and count for deployment\n",
    "instance_type = 'ml.m5.large'  \n",
    "instance_count = 1  \n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=instance_count,\n",
    "    instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "# Define your SageMaker endpoint name\n",
    "endpoint_name = 'pytorch-training-2024-10-27-18-24-52-100'\n",
    "\n",
    "# Initialize the SageMaker Predictor with the correct endpoint name\n",
    "predictor = Predictor(endpoint_name=endpoint_name)\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the S3 bucket and image path\n",
    "bucket = 'sagemaker-us-east-1-637163362320'\n",
    "image_key = 'dogImages/test/003.Airedale_terrier/Airedale_terrier_00166.jpg'\n",
    "\n",
    "# Download the image from S3\n",
    "s3.download_file(bucket, image_key, 'temp_image.jpg')\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open('temp_image.jpg')\n",
    "image = image.resize((224, 224))  \n",
    "\n",
    "# Convert the image to a byte array\n",
    "buffered = io.BytesIO()\n",
    "image.save(buffered, format=\"JPEG\")\n",
    "img_byte_array = buffered.getvalue()\n",
    "\n",
    "# Run the prediction\n",
    "response = predictor.predict(img_byte_array)\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
